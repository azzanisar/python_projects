{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install contractions cleantext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLew0ARjnYgk",
        "outputId": "586edaa5-2c77-4222-d638-b34f1690ae91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting cleantext\n",
            "  Downloading cleantext-1.1.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from cleantext) (3.8.1)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (4.65.0)\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, cleantext, contractions\n",
            "Successfully installed anyascii-0.3.2 cleantext-1.1.4 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from cleantext import clean\n",
        "import random\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "class Preprocessing_token():\n",
        "    def __init__(self,token):\n",
        "        self.token = token\n",
        "\n",
        "    # returns the expanded version of contractions\n",
        "    def remove_contractions(self, token):\n",
        "        token = contractions.fix(token.lower())\n",
        "        return token\n",
        "    \n",
        "    #convert all words to lower case\n",
        "    def remove_uppercase(self, token):\n",
        "        token = token.lower()\n",
        "        return token\n",
        "    \n",
        "    #Remove Punctuation\n",
        "    def remove_punctuation(self, token):\n",
        "        token =  re.sub('[%s]' % re.escape(string.punctuation), '' , token)\n",
        "        return token\n",
        "    \n",
        "    #Remove Numbers\n",
        "    def remove_numbers(self, token):\n",
        "        token = re.sub(r'\\d+', '', token)\n",
        "        return token\n",
        "    \n",
        "    #Remove whitespace\n",
        "    def remove_whitespace(self, token):\n",
        "        token = \" \".join(token.split()) #split text then join with space between words\n",
        "        return token\n",
        "    \n",
        "    #remove Emojis \n",
        "    def remove_emojis(self, token):\n",
        "        regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "        return regrex_pattern.sub(r'',token)\n",
        "\n",
        "    #remove html tags based on given filter tags (it basically gets the content inside given filter tags)\n",
        "    def remove_html(self,html,tags):\n",
        "      #using html parser to sort out text only \n",
        "      soup = BeautifulSoup(html, 'html.parser')\n",
        "      #scraping only title and paragraph\n",
        "      results = soup.find_all(tags)\n",
        "      #saving the results generated\n",
        "      text = [result.text for result in results]\n",
        "      ARTICLE = ' '.join(text)\n",
        "      return ARTICLE\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "J0MPVn27swCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://www.sondakika.com/politika/haber-cumhurbaskani-erdogan-eve-donus-projeleri-ile-6-bin-bilim-insanimizi-geri-kazandirdik-15822485/\"\n",
        "r = requests.get(URL)\n",
        "\n",
        "pre = Preprocessing_token(\"\")\n",
        "print(pre.remove_html(r.text,[\"h1\",\"p\"]))\n"
      ],
      "metadata": {
        "id": "XdfLO4dUw-ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602e861d-d981-4d4a-a7bd-565bac56e47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumhurbaşkanı Erdoğan: 6 bin bilim insanımızı milletimize, memleketimize geri kazandırdık Cumhurbaşkanı Recep Tayyip Erdoğan, sosyal medya üzerinden dikkat çeken bir paylaşıma imza attı. 2018 yılında hayata geçirilen Eve Dönüş Projeleri kapsamında ülkeye geri dönen bilim insanlarının sayısını veren Erdoğan, \" Türkiye, artık gidenlerin geldiği bir ülke\" dedi.  Erdoğan paylaşımına şu notu düştü:   \"2018'de hayata geçirdiğimiz Eve Dönüş Projeleri kapsamında yabancı ülkelerde faaliyet gösteren 6 bin bilim insanımızı milletimize, memleketimize geri kazandırdık. Beyin göçünü tersine çevirmeye devam edeceğiz. Çünkü Türkiye, artık gidenlerin geldiği bir ülke\"  Paylaşımda, ilköğrenimini Muş'ta tamamlayan ve yıllar sonra İngiltere'de ders vermeye başlayan bir bilim insanının, Erdoğan'ın yazdığı mektupla ülkeye geri dönüş hikayesinin anlatıldığı video da yer aldı. Videoda, \"Bu ülke birçok cevherini imkansızlıklar yüzünden kaybetti. Artık buna bir son verip yarım kalan hayallerimizi tamamlama zamanı. 2018 yılında hayata geçirdiğimiz Eve Dönüş Projeleri kapsamında yabancı ülkelerde faaliyet gösteren 6 bin bilim insanını milletimize geri kazandırdık. Bilim ve araştırmaya yapılan yatırımlar sayesinde Türkiye artık gidenlerin geldiği bir ülke.\" ifadeleri kullanıldı.  Recep Tayyip Erdoğan, Politika, Güncel, Son Dakika   Son Dakika › Politika › Cumhurbaşkanı Erdoğan: 6 bin bilim insanımızı milletimize, memleketimize geri kazandırdık - Son Dakika  Sondakika.com'un size anlık bildirim göndermesine izin veriyor musunuz?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from heapq import nlargest\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc =\"\"\"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics.\"\"\"\n",
        "\n",
        "#Cleaning\n",
        "preprocessor = Preprocessing_token(\"\")\n",
        "doc = preprocessor.remove_uppercase(doc)\n",
        "#doc = preprocessor.remove_punctuation(doc)\n",
        "doc = preprocessor.remove_numbers(doc)\n",
        "doc = preprocessor.remove_whitespace(doc)\n",
        "doc = preprocessor.remove_emojis(doc)\n",
        "doc = preprocessor.remove_contractions(doc)\n",
        "\n",
        "def summarising(doc):\n",
        "  preprocessor = Preprocessing_token(\"\")\n",
        "  doc = preprocessor.remove_uppercase(doc)\n",
        "  doc = preprocessor.remove_punctuation(doc)\n",
        "  doc = preprocessor.remove_numbers(doc)\n",
        "  doc = preprocessor.remove_whitespace(doc)\n",
        "  doc = preprocessor.remove_emojis(doc)\n",
        "  doc = preprocessor.remove_contractions(doc)\n",
        "  doc = nlp(doc)\n",
        "\n",
        "  keyword = []\n",
        "  stopwords = list(STOP_WORDS)\n",
        "  pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
        "  for token in doc:\n",
        "      if(token.text in stopwords or token.text in punctuation):\n",
        "          continue\n",
        "      if(token.pos_ in pos_tag):\n",
        "          keyword.append(token.text)\n",
        "  freq_word = Counter(keyword)\n",
        "  max_freq=Counter(keyword).most_common(1)[0][1]\n",
        "  print(max_freq)\n",
        "  for word in freq_word.keys():  \n",
        "          freq_word[word] = (freq_word[word]/max_freq)\n",
        "  sent_strength={}\n",
        "  for sent in doc.sents:\n",
        "      for word in sent:\n",
        "          if word.text in freq_word.keys():\n",
        "              if sent in sent_strength.keys():\n",
        "                  sent_strength[sent]+=freq_word[word.text]\n",
        "              else:\n",
        "                  sent_strength[sent]=freq_word[word.text]\n",
        "\n",
        "  #Set the output summarized sentence count\n",
        "  summarized_sentences = nlargest(3, sent_strength, key=sent_strength.get)\n",
        "\n",
        "\n",
        "  final_sentences = [ w.text for w in summarized_sentences ]\n",
        "  summary = ' '.join(final_sentences)\n",
        "\n",
        "  return summary\n",
        "\n",
        "URL = \"https://www.sondakika.com/politika/haber-cumhurbaskani-erdogan-eve-donus-projeleri-ile-6-bin-bilim-insanimizi-geri-kazandirdik-15822485/\"\n",
        "r = requests.get(URL)\n",
        "pre = Preprocessing_token(\"\")\n",
        "azza = pre.remove_html(r.text,[\"h1\",\"p\"])\n",
        "\n",
        "\n",
        "some_equal= summarising(azza)\n",
        "print(some_equal)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW4wvn3RoqPZ",
        "outputId": "88251348-5929-4840-8410-887fc92b7982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "cumhurbaşkanı erdoğan bin bilim insanımızı milletimize memleketimize geri kazandırdık cumhurbaşkanı recep tayyip erdoğan sosyal medya üzerinden dikkat çeken bir paylaşıma imza attı yılında hayata geçirilen eve dönüş projeleri kapsamında ülkeye geri dönen bilim insanlarının sayısını veren erdoğan türkiye artık gidenlerin geldiği bir ülke dedi erdoğan paylaşımına şyou notu düştü de hayata geçirdiğimiz eve dönüş projeleri kapsamında yabancı ülkelerde faaliyet gösteren bin bilim insanımızı milletimize memleketimize geri kazandırdık beyin göçünü tersine çevirmeye devam edeceğiz çünkü türkiye artık gidenlerin geldiği bir ülke paylaşımda ilköğrenimini muşta tamamlayan ve yıllar sonra i̇ngilterede ders vermeye başlayan bir bilim insanının erdoğanın yazdığı mektupla ülkeye geri dönüş hikayesinin anlatıldığı video da yer aldı videoda bu ülke birçok cevherini imkansızlıklar yüzünden kaybetti artık buna bir son verip yarım kalan hayallerimizi tamamlama zamanı yılında hayata geçirdiğimiz eve dönüş projeleri kapsamında yabancı ülkelerde faaliyet gösteren bin bilim insanını milletimize geri kazandırdık bilim ve araştırmaya yapılan yatırımlar sayesinde türkiye artık gidenlerin geldiği bir ülke ifadeleri kullanıldı recep tayyip erdoğan politika güncel son dakika son dakika › politika › cumhurbaşkanı erdoğan bin bilim insanımızı milletimize memleketimize geri kazandırdık son dakika sondakikacomun size anlık bildirim göndermesine izin veriyor musunuz\n"
          ]
        }
      ]
    }
  ]
}